title: "Informe"
author: "Fredy Velasquez , Pablo Escobar , Angel Higueros"
date: "14/4/2023"
output: html_document
---

{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)



## Hoja de trabajo 6: Modelos de regresion logistica

{r message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE}
library(ModelMetrics)
library(ggplot2)
library(caret)
library(dummies)
library(GGally)
data<-read.csv('train.csv')




#### 1.Cree una variable dicotómica por cada una de las categorías de la variable respuesta categórica que creó en hojas anteriores. Debería tener 3 variables dicotómicas (valores 0 y 1) una que diga si la vivienda es cara o no, media o no, económica o no.
{r message=FALSE, warning=FALSE, paged.print=FALSE}
data[is.na(data)] <- 0
#Calculo de percentiles
percentil <- quantile(data$SalePrice)
#Percentiles
estado<-c('Estado')
data$Estado<-estado
#Economica=0
#Intermedia=1
#Cara=2
data <- within(data, Estado[SalePrice<=129975] <- 0)
data$Estado[(data$SalePrice>129975 & data$SalePrice<=163000)] <- 1
data$Estado[data$SalePrice>163000] <- 2
#Modelo de Regresion logistica
porcentaje<-0.7
datos<-data
#Experimento reproducible
set.seed(123)
#Variables dicotomicas
datos<-cbind(datos,dummy(data$Estado,verbose = T))
names (datos)[85] = "Cara"
names (datos)[84] = "Intermedia"
names (datos)[83] = "Economica"
head(datos,n=3)


#### 2.Use los mismos conjuntos de entrenamiento y prueba que utilizó en las hojas anteriores.
{r}
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]


#### 3.Primer modelo

{r warning=FALSE}
#Queremos saber si una casa es cara o no
modelo<-glm(Cara~., data = train[,c('SalePrice','GrLivArea','Cara','LotFrontage','LotArea','BsmtQual','PoolArea')],family = binomial(), maxit=100)
modelo

En este modelo lo que queremos saber es si la casa es cara o no, esto mediante las variables *'SalePrice','GrLivArea','Cara','LotFrontage','LotArea','BsmtQual','PoolArea'*.

{r message=FALSE, warning=FALSE}
#Correlacion de las variables
ggpairs(datos[,c('SalePrice','GrLivArea','LotFrontage','LotArea','BsmtQual','PoolArea')])


Como se observa en la grafica anterior la mayoria de las variables tienen una buena correlacion, sobre todo la variable *SalePrice*, no obstante la variable BsmQual y PoolArea, nos indica lo contrario, donde PoolArea tiene una correlacion muy baja. Es por ello que existe la posibilidad de eliminar la variable para la prediccion, sin embargo se decidio dejar por fines didacticos. 

{r}
##Modelo con todas las variables
pred<-predict(modelo,newdata = test[,c('SalePrice','GrLivArea','LotFrontage','LotArea','BsmtQual','PoolArea')], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(test$Cara),as.factor(prediccion))


Como se observa en la matriz de confusion este modelo tuvo una precision de *98.18%*, donde obtuvo 8 casas de error, indicando que fue una buena prediccion, no obstante, mas adelante veremos si tiene o no overfitting. 

{r}
#Modelo para verificar overfitting
trainPredict<-predict(modelo,newdata = train[,c('SalePrice','GrLivArea','LotFrontage','LotArea','BsmtQual','PoolArea')], type = "response")
trainPred<- ifelse(trainPredict>0.5,1,0)
confusionMatrix(as.factor(train$Cara),as.factor(trainPred))

Se crea un modelo para pode comparar la prediccion.
{r}
#Calculo de rmse para ver si tenemos overfitting, mientras mas cercano a 0 mayor overffiting.
rmse(test$Cara,prediccion)

Tal como se observa se obtuvo un RMSE alejado de 0, esto indica que este modelo no tuvo overfitting.

{r warning=FALSE}
train_numerico<-train[,c('SalePrice','GrLivArea','Cara','LotFrontage','LotArea','BsmtQual','PoolArea')]
modeloCaret<-train(Cara~.,trControl=trainControl('none'),
                   train_numerico,
                   method='glm',family='binomial')
varImp(modeloCaret)

Y como se observa anteriormente, se muestran las mejores variables para poder predecir el estado de las casas, evidenciando que *LotFrontage* no es una variable que nos sirva para el modelo, exisitiendo de no usar esta variable, cabe mencionar que por otro lado esta variable anteriormente si tenia una buena correlacion, sin embargo aun asi no fue util para este modelo, tal es el caso contrario de la variable *PoolArea* el cual no tenia una buena correlacion, sin embargo, si influyo mucho en la prediccion del modelo. 
Y la mejor variable para predicir el estado de la casa es *SalePrice*


#### 7.Segundo modelo

{r warning=FALSE}
#Queremos saber si una casa es intermedia o no
modelo<-glm(Intermedia~., data = train[,c('GarageArea','GarageCars','Intermedia','MoSold','GarageYrBlt','MasVnrArea','MiscVal')],family = binomial(), maxit=100)
modelo

Con este modelo se busca determinar si una casa es intermedia o no, utilizando las variables *'GarageArea','GarageCars','Intermedia','MoSold','GarageYrBlt','MasVnrArea','MiscVal'*.

{r message=FALSE, warning=FALSE}
#Correlacion de las variables
ggpairs(datos[,c('GarageArea','GarageCars','MoSold','GarageYrBlt','MasVnrArea','MiscVal')])


En el gráfico anterior se observa que la mayoria de las variables no tienen buena correlación, sobre todo la variable *MiscVal, sin embargo, las variables **GarageCars* y *GarageYrBlt* sí tienen buena correlación. Entonces se puede concluir que esta combinación de variables no es la más adecuada para el modelo, pero se decidió dejar por fines didácticos.

{r}
##Modelo con todas las variables
pred<-predict(modelo,newdata = test[,c('GarageArea','GarageCars','MoSold','GarageYrBlt','MasVnrArea','MiscVal')], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(test$Intermedia),as.factor(prediccion))


Este modelo tuvo una precision de *75.63%*, tal y como se observa en la matriz de confusión mostrada anteriormente. Se obtuvieron 107 casas de error, indicando que no fue la mejor prediccion, pero si es significativa basándonos en la precisión. A continuación se observará si tiene overfitting o no. 

{r}
#Modelo para verificar overfitting
trainPredict<-predict(modelo,newdata = train[,c('GarageArea','GarageCars','MoSold','GarageYrBlt','MasVnrArea','MiscVal')], type = "response")
trainPred<- ifelse(trainPredict>0.5,1,0)
confusionMatrix(as.factor(train$Intermedia),as.factor(trainPred))

Modelo para comparar con la predicción.
{r}
#Calculo de rmse para ver si tenemos overfitting, mientras mas cercano a 0 mayor overffiting.
rmse(test$Intermedia,prediccion)

Se observa que se obtuvo un RMSE alejado de 0, siendo *0.493696*, indicando que este modelo no tiene overfitting.

{r warning=FALSE}
train_numerico<-train[,c('GarageArea','GarageCars','Intermedia','MoSold','GarageYrBlt','MasVnrArea','MiscVal')]
modeloIntet<-train(Intermedia~.,trControl=trainControl('none'),
                   train_numerico,
                   method='glm',family='binomial')
varImp(modeloIntet)

Finalmente, se muestran las mejores variables para poder predecir el estado de las casas, evidenciando que *GarageArea* no es una variable útil para el modelo y esto se afirma con su correlación mostrada anteriormente, siendo mala correlación. Respecto a la variable *GarageCars* sí es útil, influyendo en la predicción del modelo, y se observa que esta variable si tiene buena correlación. E indiscutiblemente, la mejor variable de este modelo para predicir el estado de la casa es *GarageYrBlt*.

#### 7.Tercer modelo

```{r warning=FALSE}
#Queremos saber si una casa es economica o no
modelo<-glm(Economica~., data = train[,c('TotalBsmtSF','MasVnrArea','Economica','YearRemodAdd','GrLivArea','WoodDeckSF')],family = binomial(), maxit=100)
modelo
```
Con este modelo se busca determinar si una casa es Economica o no, utilizando las variables **'TotalBsmtSF','MasVnrArea','Economica','YearRemodAdd','GrLivArea','WoodDeckSF'**.

```{r message=FALSE, warning=FALSE}
#Correlacion de las variables
ggpairs(datos[,c('TotalBsmtSF','MasVnrArea','YearRemodAdd','GrLivArea','WoodDeckSF')])
```

En el gráfico anterior se observa que la mayoria de las variables no tienen buena correlación, sobre todo la variable **WoodDeckSF**, sin embargo, las variables **MasVnrArea** y **GrLivArea** tienen una correlación medianamente correcta o por lo menos usable. Entonces se puede concluir que esta combinación de variables no es la más adecuada para el modelo, pero se quiso llegar a determinar una relacion entre areas, año de remodelacion y espacio de madera. 

```{r}
##Modelo con todas las variables
pred<-predict(modelo,newdata = test[,c('TotalBsmtSF','MasVnrArea','YearRemodAdd','GrLivArea','WoodDeckSF')], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(test$Economica),as.factor(prediccion))
```

Este modelo tuvo una precision de **87.24%**, o bien de **0.8724** tal y como se observa en la matriz de confusión mostrada anteriormente, indicando que fue una prediccion medianamente buena. A continuación se observará si tiene overfitting o no. 

```{r}

#Modelo para verificar overfitting
trainPredict<-predict(modelo,newdata = train[,c('TotalBsmtSF','MasVnrArea','YearRemodAdd','GrLivArea','WoodDeckSF')], type = "response")
trainPred<- ifelse(trainPredict>0.5,1,0)
confusionMatrix(as.factor(train$Economica),as.factor(trainPred))
```
Modelo para comparar con la predicción.
```{r}
#Calculo de rmse para ver si tenemos overfitting, mientras mas cercano a 0 mayor overffiting.
rmse(test$Economica,prediccion)

```
Se observa que se obtuvo un RMSE alejado de 0, siendo **0.3571591**, indicando que este modelo no tiene overfitting.

```{r warning=FALSE}
train_numerico<-train[,c('TotalBsmtSF','MasVnrArea', 'Economica','YearRemodAdd','GrLivArea','WoodDeckSF')]
modeloCaret<-train(Economica~.,trControl=trainControl('none'),
                   train_numerico,
                   method='glm',family='binomial')
varImp(modeloCaret)

En el gráfico anterior se observa que solo 3 de las variables tienen buena correlación, sobre todo la variable **YearRemodAdd**, sin embargo, las variables **TotalBsmtSF** y **GrLivArea** tienen una correlación bastabte correcta. Mientras que las variables **WoodDeckSF** y **MasVnrArea**, son las peores, sobre todo la ultima varaible. 

#### 9. ¿Hay alguna forma de mejorar los modelos usando parámetros?¿ Serviría usar regularización en el caso de los modelos creados? 

